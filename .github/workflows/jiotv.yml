name: Update Zootv Cookies

permissions:
  contents: write

on:
  schedule:
    - cron: '0 */6 * * *'  # Every 6 hours
  workflow_dispatch:  # Manual trigger

jobs:
  update-cookies:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests

      - name: Update Cookies in Zootv.json
        run: |
          python -c "
          import json
          import requests
          from urllib.parse import urlparse
          import re
          import os

          API_URL = 'https://jo-json.vodep39240327.workers.dev'
          PLAYLIST_FILE = 'Zootv.json'

          def fetch_channel_data():
              try:
                  response = requests.get(API_URL, timeout=30)
                  response.raise_for_status()
                  data = response.json()
                  print(f'‚úÖ Fetched {len(data)} channels from source.')
                  return data
              except Exception as e:
                  print(f'‚ùå Error fetching data: {e}')
                  return None

          def load_playlist():
              try:
                  with open(PLAYLIST_FILE, 'r', encoding='utf-8') as f:
                      playlist = json.load(f)
                  print(f'‚úÖ Loaded {len(playlist)} channels from {PLAYLIST_FILE}.')
                  return playlist
              except FileNotFoundError:
                  print('‚ö†Ô∏è Zootv.json not found. Exiting.')
                  exit(1)
              except Exception as e:
                  print(f'‚ùå Error loading playlist: {e}')
                  exit(1)

          def save_playlist(playlist):
              try:
                  with open(PLAYLIST_FILE, 'w', encoding='utf-8') as f:
                      json.dump(playlist, f, indent=2, ensure_ascii=False)
                  print(f'‚úÖ Playlist saved with {len(playlist)} channels!')
              except Exception as e:
                  print(f'‚ùå Error saving playlist: {e}')
                  exit(1)

          def extract_cookie_from_url(url):
              try:
                  parsed_url = urlparse(url)
                  query = parsed_url.query
                  match = re.search(r'__hdnea__=([^&]*)', query)
                  if match:
                      cookie_value = match.group(1)
                      cookie = f'__hdnea__={cookie_value}'
                      print(f'üç™ Extracted cookie: {cookie[:50]}...')
                      return cookie
                  print(f'‚ö†Ô∏è No __hdnea__ cookie found in URL: {url}')
                  return 'no_cookie_available'
              except Exception as e:
                  print(f'‚ùå Error extracting cookie: {e}')
                  return 'no_cookie_available'

          def extract_channel_name_from_url(url):
              try:
                  parsed_url = urlparse(url)
                  path = parsed_url.path
                  match = re.search(r'/bpk-tv/([^/]+)(?:/WDVLive|/output)/index\.mpd', path)
                  if match:
                      raw_name = match.group(1)
                      clean_name = re.sub(r'_BTS|_MOB', '', raw_name).replace('_', ' ').strip()
                      return clean_name if clean_name else 'Unknown'
                  print(f'‚ö†Ô∏è No channel name found in URL: {url}')
                  return None
              except Exception as e:
                  print(f'‚ùå Error extracting channel name: {e}')
                  return None

          def update_cookies(playlist, fresh_data):
              updated_count = 0
              existing_channels = {extract_channel_name_from_url(ch['link']): ch for ch in playlist if extract_channel_name_from_url(ch['link'])}

              for channel_id, data in fresh_data.items():
                  try:
                      url = data.get('url', '')
                      if not url:
                          print(f'‚ö†Ô∏è Skipped {channel_id}: Missing URL')
                          continue

                      cookie = extract_cookie_from_url(url)
                      channel_name = extract_channel_name_from_url(url)
                      if not channel_name:
                          print(f'‚ö†Ô∏è Skipped {channel_id}: Could not extract channel name')
                          continue

                      if channel_name in existing_channels:
                          existing_channels[channel_name]['cookie'] = cookie
                          updated_count += 1
                          print(f'üîÑ Updated cookie for {channel_name} ({channel_id})')
                      else:
                          print(f'‚ö†Ô∏è Skipped {channel_name} ({channel_id}): Channel not in playlist')

                  except Exception as e:
                      print(f'‚ùå Error processing {channel_id}: {e}')

              print(f'üìä Cookies Updated: {updated_count}')
              return playlist

          def main():
              print('üöÄ Starting cookie update...')
              fresh_data = fetch_channel_data()
              if not fresh_data:
                  print('‚ùå No data fetched. Exiting.')
                  exit(1)
              playlist = load_playlist()
              updated_playlist = update_cookies(playlist, fresh_data)
              save_playlist(updated_playlist)
              print('üéâ Cookie update complete!')

          if __name__ == '__main__':
              main()
          "

      - name: Commit and Push Changes
        uses: EndBug/add-and-commit@v9
        with:
          message: 'Auto-update cookies in Zootv.json'
          add: 'Zootv.json'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
